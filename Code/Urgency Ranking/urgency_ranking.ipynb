{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"KFLXEzDa7tp4","outputId":"e179fe31-0341-4d6c-8f26-8af33c35b3a9"},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","from transformers import BertTokenizer, BertModel\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","# Check if CUDA is available and set the device accordingly\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Sample data (replace with your actual data source)\n","df = pd.read_csv('.../final_clustered_tweets.csv')\n","\n","# Load pre-trained BERT model\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertModel.from_pretrained('bert-base-uncased')\n","\n","# Move the model to the GPU if available\n","model.to(device)\n","model.eval()\n","\n","# Define grouped and individual keywords\n","grouped_keywords = {\n","    'high_grouped': [\n","        ['stranded', 'trapped', 'injured'],\n","        ['emergency', 'urgent', 'SOS'],\n","        ['danger', 'alert', 'casualty'],\n","        ['dead', 'evacuate', 'death'],\n","        ['flooding', 'missing', 'evacuating'],\n","        ['disaster', 'destroyed', 'mandatory evacuation'],\n","        ['quake hit', 'category storm'],\n","        ['newborns', 'children', 'women', 'injured']\n","    ],\n","    'medium_grouped': [\n","        ['rescue', 'help', 'helpline'],\n","        ['newborns intensive care', 'care flown'],\n","        ['lost', 'response', 'families'],\n","        ['hit', 'quake', 'killed'],\n","        ['victim', 'toll', 'hospital'],\n","        ['flee texas', 'damage', 'shelter'],\n","        ['redcross', 'food', 'building'],\n","        ['hit nepal', 'pet', 'thousands flee'],\n","        ['biggest flood', 'help nepal']\n","    ],\n","    'low_grouped': [\n","        ['rain', 'reports', 'service'],\n","        ['donate', 'donation', 'safety'],\n","        ['donated', 'support', 'intensive care'],\n","        ['contact', 'safety', 'unicef'],\n","        ['million', 'contact']\n","    ]\n","}\n","\n","individual_keywords = {\n","    'high_individual': ['stranded', 'trapped', 'injure', 'emergency', 'urgent', 'SOS', 'danger', 'alert', 'casualty', 'injured', 'dead', 'evacuate', 'death', 'flooding', 'missing', 'evacuating', 'disaster', 'destroyed', 'mandatory evacuation', 'quake hit', 'category storm', 'newborns', 'children', 'women'],\n","    'medium_individual': ['rescue', 'help', 'helpline', 'newborns intensive care', 'care flown', 'texas officials', 'lost', 'response', 'families', 'hit', 'quake', 'killed', 'victim', 'toll', 'hospital', 'flee texas', 'damage', 'shelter', 'redcross', 'food', 'building', 'hit nepal', 'pet', 'thousands flee', 'biggest flood', 'help nepal'],\n","    'low_individual': ['rain', 'reports', 'service', 'donate', 'donation', 'safety', 'donated', 'support', 'intensive care', 'contact', 'safety', 'unicef', 'million', 'contact']\n","}\n","\n","weights = {\n","    'high_grouped': 6,\n","    'high_individual': 5,\n","    'medium_grouped': 4,\n","    'medium_individual': 3,\n","    'low_grouped': 2,\n","    'low_individual': 1\n","}\n","\n","\n","# Function to compute BERT vector for a tweet\n","def bert_tweet_vector(tweet, tokenizer, model, device):\n","    inputs = tokenizer(tweet, return_tensors=\"pt\", max_length=512, truncation=True)\n","    inputs = {k: v.to(device) for k, v in inputs.items()}  # Move input to GPU\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","    cls_embedding = outputs.last_hidden_state[:, 0, :].detach().cpu().numpy()\n","    return cls_embedding.reshape(1, -1)  # Reshape to 2D array\n","\n","# Function to compute group vector\n","def compute_group_vector(group, tokenizer, model, device):\n","    group_vecs = [bert_tweet_vector(keyword, tokenizer, model, device) for keyword in group]\n","    return np.mean(group_vecs, axis=0)\n","\n","# Function to compute urgency score\n","def compute_urgency_score_bert(tweet, tokenizer, model, grouped_keywords, individual_keywords, weights, device):\n","    tweet_vec = bert_tweet_vector(tweet, tokenizer, model, device)\n","    total_score = 0\n","\n","    # Handle grouped keywords\n","    for category, groups in grouped_keywords.items():\n","        for group in groups:\n","            group_vec = compute_group_vector(group, tokenizer, model, device)\n","            total_score += cosine_similarity(tweet_vec, group_vec)[0][0] * weights[category]\n","\n","    # Handle individual keywords\n","    for category, keywords in individual_keywords.items():\n","        for keyword in keywords:\n","            keyword_vec = bert_tweet_vector(keyword, tokenizer, model, device)\n","            total_score += cosine_similarity(tweet_vec, keyword_vec)[0][0] * weights[category]\n","\n","    return total_score\n","\n","# Compute weighted urgency scores\n","df['urgency_score'] = df['tidy_tweet'].apply(lambda x: compute_urgency_score_bert(x, tokenizer, model, grouped_keywords, individual_keywords, weights, device))\n","\n","# Rank tweets based on urgency scores\n","ranked_tweets = df.sort_values(by='urgency_score', ascending=False)\n","\n","# Display top-ranked tweets\n","print(ranked_tweets[['tweet_id', 'tidy_tweet', 'urgency_score']].head(10))\n","\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}